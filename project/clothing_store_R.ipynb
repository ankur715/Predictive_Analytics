{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clothing Store\n",
    "### - _Ankur Patel_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction:\n",
    "\n",
    "The Clothing_store_training_test data set contains information about customers on the 119 variables. The target variable is the Response of 1 or 0, which is True or False. A classification model will be developed to maximize profits for direct-mail marketing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: lattice\n",
      "Loading required package: ggplot2\n"
     ]
    }
   ],
   "source": [
    "# read library\n",
    "library(caret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>HHKEY</th><th scope=col>ZIP_CODE</th><th scope=col>REC</th><th scope=col>FRE</th><th scope=col>MON</th><th scope=col>CC_CARD</th><th scope=col>AVRG</th><th scope=col>PC_CALC20</th><th scope=col>PSWEATERS</th><th scope=col>PKNIT_TOPS</th><th scope=col>...</th><th scope=col>ln.lifetime.ave.time.betw.visits</th><th scope=col>ln.product.uniformity</th><th scope=col>sqrt.responded</th><th scope=col>flag.returns</th><th scope=col>flag.response.rate</th><th scope=col>flag.markdown</th><th scope=col>sqrt.spending.months.2.3</th><th scope=col>sqrt.spending.months.4.5.6</th><th scope=col>flag.spending.months.4.5.6</th><th scope=col>flag.spending.months.2.3</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>9.9556e+12</td><td>1001      </td><td>208       </td><td>2         </td><td>368.46    </td><td>0         </td><td>184.23    </td><td>11        </td><td>0.18      </td><td>0.00      </td><td>...       </td><td>4.709530  </td><td>3.459781  </td><td>0.000000  </td><td>FALSE     </td><td>FALSE     </td><td>TRUE      </td><td> 0.000000 </td><td> 0.000000 </td><td>FALSE     </td><td>FALSE     </td></tr>\n",
       "\t<tr><td>9.9556e+12</td><td>1028      </td><td>  6       </td><td>4         </td><td>258.00    </td><td>1         </td><td> 64.50    </td><td>11        </td><td>0.26      </td><td>0.16      </td><td>...       </td><td>3.772761  </td><td>3.487987  </td><td>1.414214  </td><td> TRUE     </td><td> TRUE     </td><td>TRUE      </td><td> 9.055937 </td><td>10.954451 </td><td> TRUE     </td><td> TRUE     </td></tr>\n",
       "\t<tr><td>9.9556e+12</td><td>1056      </td><td>327       </td><td>2         </td><td> 77.00    </td><td>0         </td><td> 38.50    </td><td>11        </td><td>1.00      </td><td>0.00      </td><td>...       </td><td>4.228293  </td><td>4.605170  </td><td>0.000000  </td><td>FALSE     </td><td>FALSE     </td><td>TRUE      </td><td> 0.000000 </td><td> 0.000000 </td><td>FALSE     </td><td>FALSE     </td></tr>\n",
       "\t<tr><td>9.9556e+12</td><td>1118      </td><td> 66       </td><td>8         </td><td>846.06    </td><td>1         </td><td>105.75    </td><td>11        </td><td>0.38      </td><td>0.00      </td><td>...       </td><td>3.294354  </td><td>3.147165  </td><td>2.449490  </td><td>FALSE     </td><td> TRUE     </td><td>TRUE      </td><td>10.244023 </td><td>16.399085 </td><td> TRUE     </td><td> TRUE     </td></tr>\n",
       "\t<tr><td>9.9556e+12</td><td>1107      </td><td> 49       </td><td>1         </td><td> 87.44    </td><td>0         </td><td> 87.44    </td><td>11        </td><td>0.20      </td><td>0.20      </td><td>...       </td><td>3.198673  </td><td>3.350606  </td><td>0.000000  </td><td>FALSE     </td><td>FALSE     </td><td>TRUE      </td><td> 9.350936 </td><td> 0.000000 </td><td>FALSE     </td><td> TRUE     </td></tr>\n",
       "\t<tr><td>9.9556e+12</td><td>1106      </td><td> 26       </td><td>2         </td><td>120.00    </td><td>0         </td><td> 60.00    </td><td>11        </td><td>0.00      </td><td>0.56      </td><td>...       </td><td>4.283587  </td><td>3.888550  </td><td>0.000000  </td><td>FALSE     </td><td>FALSE     </td><td>TRUE      </td><td> 0.000000 </td><td> 7.615773 </td><td> TRUE     </td><td>FALSE     </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       " HHKEY & ZIP\\_CODE & REC & FRE & MON & CC\\_CARD & AVRG & PC\\_CALC20 & PSWEATERS & PKNIT\\_TOPS & ... & ln.lifetime.ave.time.betw.visits & ln.product.uniformity & sqrt.responded & flag.returns & flag.response.rate & flag.markdown & sqrt.spending.months.2.3 & sqrt.spending.months.4.5.6 & flag.spending.months.4.5.6 & flag.spending.months.2.3\\\\\n",
       "\\hline\n",
       "\t 9.9556e+12 & 1001       & 208        & 2          & 368.46     & 0          & 184.23     & 11         & 0.18       & 0.00       & ...        & 4.709530   & 3.459781   & 0.000000   & FALSE      & FALSE      & TRUE       &  0.000000  &  0.000000  & FALSE      & FALSE     \\\\\n",
       "\t 9.9556e+12 & 1028       &   6        & 4          & 258.00     & 1          &  64.50     & 11         & 0.26       & 0.16       & ...        & 3.772761   & 3.487987   & 1.414214   &  TRUE      &  TRUE      & TRUE       &  9.055937  & 10.954451  &  TRUE      &  TRUE     \\\\\n",
       "\t 9.9556e+12 & 1056       & 327        & 2          &  77.00     & 0          &  38.50     & 11         & 1.00       & 0.00       & ...        & 4.228293   & 4.605170   & 0.000000   & FALSE      & FALSE      & TRUE       &  0.000000  &  0.000000  & FALSE      & FALSE     \\\\\n",
       "\t 9.9556e+12 & 1118       &  66        & 8          & 846.06     & 1          & 105.75     & 11         & 0.38       & 0.00       & ...        & 3.294354   & 3.147165   & 2.449490   & FALSE      &  TRUE      & TRUE       & 10.244023  & 16.399085  &  TRUE      &  TRUE     \\\\\n",
       "\t 9.9556e+12 & 1107       &  49        & 1          &  87.44     & 0          &  87.44     & 11         & 0.20       & 0.20       & ...        & 3.198673   & 3.350606   & 0.000000   & FALSE      & FALSE      & TRUE       &  9.350936  &  0.000000  & FALSE      &  TRUE     \\\\\n",
       "\t 9.9556e+12 & 1106       &  26        & 2          & 120.00     & 0          &  60.00     & 11         & 0.00       & 0.56       & ...        & 4.283587   & 3.888550   & 0.000000   & FALSE      & FALSE      & TRUE       &  0.000000  &  7.615773  &  TRUE      & FALSE     \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| HHKEY | ZIP_CODE | REC | FRE | MON | CC_CARD | AVRG | PC_CALC20 | PSWEATERS | PKNIT_TOPS | ... | ln.lifetime.ave.time.betw.visits | ln.product.uniformity | sqrt.responded | flag.returns | flag.response.rate | flag.markdown | sqrt.spending.months.2.3 | sqrt.spending.months.4.5.6 | flag.spending.months.4.5.6 | flag.spending.months.2.3 |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 9.9556e+12 | 1001       | 208        | 2          | 368.46     | 0          | 184.23     | 11         | 0.18       | 0.00       | ...        | 4.709530   | 3.459781   | 0.000000   | FALSE      | FALSE      | TRUE       |  0.000000  |  0.000000  | FALSE      | FALSE      |\n",
       "| 9.9556e+12 | 1028       |   6        | 4          | 258.00     | 1          |  64.50     | 11         | 0.26       | 0.16       | ...        | 3.772761   | 3.487987   | 1.414214   |  TRUE      |  TRUE      | TRUE       |  9.055937  | 10.954451  |  TRUE      |  TRUE      |\n",
       "| 9.9556e+12 | 1056       | 327        | 2          |  77.00     | 0          |  38.50     | 11         | 1.00       | 0.00       | ...        | 4.228293   | 4.605170   | 0.000000   | FALSE      | FALSE      | TRUE       |  0.000000  |  0.000000  | FALSE      | FALSE      |\n",
       "| 9.9556e+12 | 1118       |  66        | 8          | 846.06     | 1          | 105.75     | 11         | 0.38       | 0.00       | ...        | 3.294354   | 3.147165   | 2.449490   | FALSE      |  TRUE      | TRUE       | 10.244023  | 16.399085  |  TRUE      |  TRUE      |\n",
       "| 9.9556e+12 | 1107       |  49        | 1          |  87.44     | 0          |  87.44     | 11         | 0.20       | 0.20       | ...        | 3.198673   | 3.350606   | 0.000000   | FALSE      | FALSE      | TRUE       |  9.350936  |  0.000000  | FALSE      |  TRUE      |\n",
       "| 9.9556e+12 | 1106       |  26        | 2          | 120.00     | 0          |  60.00     | 11         | 0.00       | 0.56       | ...        | 4.283587   | 3.888550   | 0.000000   | FALSE      | FALSE      | TRUE       |  0.000000  |  7.615773  |  TRUE      | FALSE      |\n",
       "\n"
      ],
      "text/plain": [
       "  HHKEY      ZIP_CODE REC FRE MON    CC_CARD AVRG   PC_CALC20 PSWEATERS\n",
       "1 9.9556e+12 1001     208 2   368.46 0       184.23 11        0.18     \n",
       "2 9.9556e+12 1028       6 4   258.00 1        64.50 11        0.26     \n",
       "3 9.9556e+12 1056     327 2    77.00 0        38.50 11        1.00     \n",
       "4 9.9556e+12 1118      66 8   846.06 1       105.75 11        0.38     \n",
       "5 9.9556e+12 1107      49 1    87.44 0        87.44 11        0.20     \n",
       "6 9.9556e+12 1106      26 2   120.00 0        60.00 11        0.00     \n",
       "  PKNIT_TOPS ... ln.lifetime.ave.time.betw.visits ln.product.uniformity\n",
       "1 0.00       ... 4.709530                         3.459781             \n",
       "2 0.16       ... 3.772761                         3.487987             \n",
       "3 0.00       ... 4.228293                         4.605170             \n",
       "4 0.00       ... 3.294354                         3.147165             \n",
       "5 0.20       ... 3.198673                         3.350606             \n",
       "6 0.56       ... 4.283587                         3.888550             \n",
       "  sqrt.responded flag.returns flag.response.rate flag.markdown\n",
       "1 0.000000       FALSE        FALSE              TRUE         \n",
       "2 1.414214        TRUE         TRUE              TRUE         \n",
       "3 0.000000       FALSE        FALSE              TRUE         \n",
       "4 2.449490       FALSE         TRUE              TRUE         \n",
       "5 0.000000       FALSE        FALSE              TRUE         \n",
       "6 0.000000       FALSE        FALSE              TRUE         \n",
       "  sqrt.spending.months.2.3 sqrt.spending.months.4.5.6\n",
       "1  0.000000                 0.000000                 \n",
       "2  9.055937                10.954451                 \n",
       "3  0.000000                 0.000000                 \n",
       "4 10.244023                16.399085                 \n",
       "5  9.350936                 0.000000                 \n",
       "6  0.000000                 7.615773                 \n",
       "  flag.spending.months.4.5.6 flag.spending.months.2.3\n",
       "1 FALSE                      FALSE                   \n",
       "2  TRUE                       TRUE                   \n",
       "3 FALSE                      FALSE                   \n",
       "4  TRUE                       TRUE                   \n",
       "5 FALSE                       TRUE                   \n",
       "6  TRUE                      FALSE                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reading the clothing_store_training_test dataset\n",
    "df = read.csv(file.choose())\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t2847 obs. of  119 variables:\n",
      " $ HHKEY                           : num  9.96e+12 9.96e+12 9.96e+12 9.96e+12 9.96e+12 ...\n",
      " $ ZIP_CODE                        : int  1001 1028 1056 1118 1107 1106 1108 1106 1118 1106 ...\n",
      " $ REC                             : int  208 6 327 66 49 26 98 64 145 356 ...\n",
      " $ FRE                             : int  2 4 2 8 1 2 3 5 1 1 ...\n",
      " $ MON                             : num  368.5 258 77 846.1 87.4 ...\n",
      " $ CC_CARD                         : int  0 1 0 1 0 0 0 1 1 0 ...\n",
      " $ AVRG                            : num  184.2 64.5 38.5 105.8 87.4 ...\n",
      " $ PC_CALC20                       : int  11 11 11 11 11 11 11 11 11 11 ...\n",
      " $ PSWEATERS                       : num  0.18 0.26 1 0.38 0.2 0 0.16 0.16 0.12 0 ...\n",
      " $ PKNIT_TOPS                      : num  0 0.16 0 0 0.2 0.56 0.06 0.07 0 0 ...\n",
      " $ PKNIT_DRES                      : num  0 0 0 0.05 0 0 0 0 0 0 ...\n",
      " $ PBLOUSES                        : num  0.3 0 0 0.06 0 0 0 0.05 0 0 ...\n",
      " $ PJACKETS                        : num  0 0 0 0.2 0 0 0.36 0.23 0.57 0 ...\n",
      " $ PCAR_PNTS                       : num  0.25 0.18 0 0.17 0 0 0.14 0 0.12 0 ...\n",
      " $ PCAS_PNTS                       : num  0 0.14 0 0 0.41 0 0.12 0.07 0 1 ...\n",
      " $ PSHIRTS                         : num  0.19 0 0 0.05 0 0 0 0.06 0.17 0 ...\n",
      " $ PDRESSES                        : num  0 0.18 0 0 0 0 0 0.25 0 0 ...\n",
      " $ PSUITS                          : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ POUTERWEAR                      : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PJEWELRY                        : num  0 0 0 0.00531 0.17 ...\n",
      " $ PFASHION                        : num  0.02 0 0 0.03 0 0.4 0.11 0 0 0 ...\n",
      " $ PLEGWEAR                        : num  0.03 0.02 0 0.01 0 0 0 0.01 0 0 ...\n",
      " $ PCOLLSPND                       : num  0.29 0.37 0 0 0 0 0 0 0 0 ...\n",
      " $ AMSPEND                         : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ PSSPEND                         : num  0 0 0 0 0 58 0 0 0 0 ...\n",
      " $ CCSPEND                         : num  368.5 258 77 846.1 87.4 ...\n",
      " $ AXSPEND                         : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ TMONSPEND                       : num  0 138 0 104.9 87.4 ...\n",
      " $ OMONSPEND                       : num  0 56 0 0 0 ...\n",
      " $ SMONSPEND                       : num  0 258 0 373.9 87.4 ...\n",
      " $ PREVPD                          : num  0 0 39 166 0 ...\n",
      " $ GMP                             : num  0.6 0.54 0.62 0.43 0.22 0.47 0.41 0.61 0.66 0.56 ...\n",
      " $ PROMOS                          : int  17 14 10 24 0 3 21 17 15 6 ...\n",
      " $ DAYS                            : int  666 696 343 701 49 145 639 357 145 447 ...\n",
      " $ FREDAYS                         : num  333 174 171.5 87.6 49 ...\n",
      " $ MARKDOWN                        : num  0.08 0.33 0.11 0.29 0.42 0.41 0.29 0.12 0.1 0.19 ...\n",
      " $ CLASSES                         : int  9 6 1 15 4 3 12 11 4 1 ...\n",
      " $ COUPONS                         : int  1 0 0 3 0 0 2 0 1 0 ...\n",
      " $ STYLES                          : int  11 14 2 35 8 5 19 17 13 2 ...\n",
      " $ STORES                          : int  1 1 1 1 1 2 1 1 1 1 ...\n",
      " $ STORELOY                        : int  7 7 7 7 7 7 7 7 7 7 ...\n",
      " $ VALPHON                         : Factor w/ 3 levels \"\",\"N\",\"Y\": 2 3 2 3 3 3 3 3 3 3 ...\n",
      " $ WEB                             : int  0 0 0 0 0 0 0 1 0 0 ...\n",
      " $ MAILED                          : int  5 4 4 9 0 0 10 4 4 4 ...\n",
      " $ RESPONDED                       : int  0 2 0 6 0 0 3 0 0 1 ...\n",
      " $ RESPONSERATE                    : num  0 50 0 66.7 0 ...\n",
      " $ HI                              : num  31.8 32.7 100 23.3 28.5 ...\n",
      " $ LTFREDAY                        : num  111 43.5 68.6 27 24.5 ...\n",
      " $ CLUSTYPE                        : int  10 10 16 10 20 3 8 20 10 10 ...\n",
      " $ PERCRET                         : num  0 0.03 0 0 0 0 0 0.05 0 0 ...\n",
      " $ RESP                            : int  0 1 0 0 0 0 0 1 0 0 ...\n",
      " $ Tot_Spend                       : num  368.5 258 77 846.1 87.4 ...\n",
      " $ Sales.per.Visit                 : num  184.2 64.5 38.5 105.8 87.4 ...\n",
      " $ Spending_Month_2_3              : num  0 82 0 104.9 87.4 ...\n",
      " $ Spending_Month_4_5_6            : num  0 120 0 269 0 ...\n",
      " $ bc.purchase.visits              : num  0.431 0.583 0.431 0.637 0 ...\n",
      " $ ln.total.net.sales              : num  5.91 5.55 4.34 6.74 4.47 ...\n",
      " $ ln_ave.spending.per.visit       : num  5.22 4.17 3.65 4.66 4.47 ...\n",
      " $ sqrt.sweaters                   : num  0.424 0.51 1 0.616 0.447 ...\n",
      " $ sqrt.knit.tops                  : num  0 0.4 0 0 0.447 ...\n",
      " $ sqrt.knit.dresses               : num  0 0 0 0.224 0 ...\n",
      " $ sqrt.blouses                    : num  0.548 0 0 0.245 0 ...\n",
      " $ sqrt.jackets                    : num  0 0 0 0.447 0 ...\n",
      " $ sqrt.career.pants               : num  0.5 0.424 0 0.412 0 ...\n",
      " $ sqrt.casual.pants               : num  0 0.374 0 0 0.64 ...\n",
      " $ sqrt.shirts                     : num  0.436 0 0 0.224 0 ...\n",
      " $ sqrt.dresses                    : num  0 0.424 0 0 0 ...\n",
      " $ sqrt.suits                      : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ sqrt.outerwear                  : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ sqrt.jewelry                    : num  0 0 0 0.0728 0.4123 ...\n",
      " $ sqrt.fashion                    : num  0.141 0 0 0.173 0 ...\n",
      " $ sqrt.legwear                    : num  0.173 0.141 0 0.1 0 ...\n",
      " $ sqrt.collectibles               : num  0.539 0.608 0 0 0 ...\n",
      " $ flag.sweaters                   : logi  TRUE TRUE TRUE TRUE TRUE FALSE ...\n",
      " $ flag.knit.tops                  : logi  FALSE TRUE FALSE FALSE TRUE TRUE ...\n",
      " $ flag.knit.dresses               : logi  FALSE FALSE FALSE TRUE FALSE FALSE ...\n",
      " $ flag.blouses                    : logi  TRUE FALSE FALSE TRUE FALSE FALSE ...\n",
      " $ flag.jackets                    : logi  FALSE FALSE FALSE TRUE FALSE FALSE ...\n",
      " $ flag.career.pants               : logi  TRUE TRUE FALSE TRUE FALSE FALSE ...\n",
      " $ flag.casual.pants               : logi  FALSE TRUE FALSE FALSE TRUE FALSE ...\n",
      " $ flag.shirts                     : logi  TRUE FALSE FALSE TRUE FALSE FALSE ...\n",
      " $ flag.dresses                    : logi  FALSE TRUE FALSE FALSE FALSE FALSE ...\n",
      " $ flag.suits                      : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ flag.outerwear                  : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ flag.jewelry                    : logi  FALSE FALSE FALSE TRUE TRUE TRUE ...\n",
      " $ flag.fashion                    : logi  TRUE FALSE FALSE TRUE FALSE TRUE ...\n",
      " $ flag.legwear                    : logi  TRUE TRUE FALSE TRUE FALSE FALSE ...\n",
      " $ flag.collectibles               : logi  TRUE TRUE FALSE FALSE FALSE FALSE ...\n",
      " $ sqrt.spending.AM                : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ sqrt.spending.PS                : num  0 0 0 0 0 ...\n",
      " $ sqrt.spending.CC                : num  19.2 16.06 8.77 29.09 9.35 ...\n",
      " $ sqrt.spending.AX                : num  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ sqrt.spending.last.three.months : num  0 11.75 0 10.24 9.35 ...\n",
      " $ sqrt.spending.last.one.month    : num  0 7.48 0 0 0 ...\n",
      " $ sqrt.spending.last.six.months   : num  0 16.06 0 19.34 9.35 ...\n",
      " $ sqrt.spending.SPLY              : num  0 0 6.24 12.89 0 ...\n",
      " $ flag.spending.AM                : logi  FALSE FALSE FALSE FALSE FALSE FALSE ...\n",
      " $ flag.spending.PS                : logi  FALSE FALSE FALSE FALSE FALSE TRUE ...\n",
      " $ flag.spending.CC                : logi  TRUE TRUE TRUE TRUE TRUE TRUE ...\n",
      "  [list output truncated]\n"
     ]
    }
   ],
   "source": [
    "# dataset size and datatype of variables\n",
    "str(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop any incomplete records\n",
    "df = df[complete.cases(df),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'HHKEY'</li>\n",
       "\t<li>'ZIP_CODE'</li>\n",
       "\t<li>'REC'</li>\n",
       "\t<li>'FRE'</li>\n",
       "\t<li>'MON'</li>\n",
       "\t<li>'CC_CARD'</li>\n",
       "\t<li>'AVRG'</li>\n",
       "\t<li>'PC_CALC20'</li>\n",
       "\t<li>'PSWEATERS'</li>\n",
       "\t<li>'PKNIT_TOPS'</li>\n",
       "\t<li>'PKNIT_DRES'</li>\n",
       "\t<li>'PBLOUSES'</li>\n",
       "\t<li>'PJACKETS'</li>\n",
       "\t<li>'PCAR_PNTS'</li>\n",
       "\t<li>'PCAS_PNTS'</li>\n",
       "\t<li>'PSHIRTS'</li>\n",
       "\t<li>'PDRESSES'</li>\n",
       "\t<li>'PSUITS'</li>\n",
       "\t<li>'POUTERWEAR'</li>\n",
       "\t<li>'PJEWELRY'</li>\n",
       "\t<li>'PFASHION'</li>\n",
       "\t<li>'PLEGWEAR'</li>\n",
       "\t<li>'PCOLLSPND'</li>\n",
       "\t<li>'AMSPEND'</li>\n",
       "\t<li>'PSSPEND'</li>\n",
       "\t<li>'CCSPEND'</li>\n",
       "\t<li>'AXSPEND'</li>\n",
       "\t<li>'TMONSPEND'</li>\n",
       "\t<li>'OMONSPEND'</li>\n",
       "\t<li>'SMONSPEND'</li>\n",
       "\t<li>'PREVPD'</li>\n",
       "\t<li>'GMP'</li>\n",
       "\t<li>'PROMOS'</li>\n",
       "\t<li>'DAYS'</li>\n",
       "\t<li>'FREDAYS'</li>\n",
       "\t<li>'MARKDOWN'</li>\n",
       "\t<li>'CLASSES'</li>\n",
       "\t<li>'COUPONS'</li>\n",
       "\t<li>'STYLES'</li>\n",
       "\t<li>'STORES'</li>\n",
       "\t<li>'STORELOY'</li>\n",
       "\t<li>'VALPHON'</li>\n",
       "\t<li>'WEB'</li>\n",
       "\t<li>'MAILED'</li>\n",
       "\t<li>'RESPONDED'</li>\n",
       "\t<li>'RESPONSERATE'</li>\n",
       "\t<li>'HI'</li>\n",
       "\t<li>'LTFREDAY'</li>\n",
       "\t<li>'CLUSTYPE'</li>\n",
       "\t<li>'PERCRET'</li>\n",
       "\t<li>'RESP'</li>\n",
       "\t<li>'Tot_Spend'</li>\n",
       "\t<li>'Sales.per.Visit'</li>\n",
       "\t<li>'Spending_Month_2_3'</li>\n",
       "\t<li>'Spending_Month_4_5_6'</li>\n",
       "\t<li>'bc.purchase.visits'</li>\n",
       "\t<li>'ln.total.net.sales'</li>\n",
       "\t<li>'ln_ave.spending.per.visit'</li>\n",
       "\t<li>'sqrt.sweaters'</li>\n",
       "\t<li>'sqrt.knit.tops'</li>\n",
       "\t<li>'sqrt.knit.dresses'</li>\n",
       "\t<li>'sqrt.blouses'</li>\n",
       "\t<li>'sqrt.jackets'</li>\n",
       "\t<li>'sqrt.career.pants'</li>\n",
       "\t<li>'sqrt.casual.pants'</li>\n",
       "\t<li>'sqrt.shirts'</li>\n",
       "\t<li>'sqrt.dresses'</li>\n",
       "\t<li>'sqrt.suits'</li>\n",
       "\t<li>'sqrt.outerwear'</li>\n",
       "\t<li>'sqrt.jewelry'</li>\n",
       "\t<li>'sqrt.fashion'</li>\n",
       "\t<li>'sqrt.legwear'</li>\n",
       "\t<li>'sqrt.collectibles'</li>\n",
       "\t<li>'flag.sweaters'</li>\n",
       "\t<li>'flag.knit.tops'</li>\n",
       "\t<li>'flag.knit.dresses'</li>\n",
       "\t<li>'flag.blouses'</li>\n",
       "\t<li>'flag.jackets'</li>\n",
       "\t<li>'flag.career.pants'</li>\n",
       "\t<li>'flag.casual.pants'</li>\n",
       "\t<li>'flag.shirts'</li>\n",
       "\t<li>'flag.dresses'</li>\n",
       "\t<li>'flag.suits'</li>\n",
       "\t<li>'flag.outerwear'</li>\n",
       "\t<li>'flag.jewelry'</li>\n",
       "\t<li>'flag.fashion'</li>\n",
       "\t<li>'flag.legwear'</li>\n",
       "\t<li>'flag.collectibles'</li>\n",
       "\t<li>'sqrt.spending.AM'</li>\n",
       "\t<li>'sqrt.spending.PS'</li>\n",
       "\t<li>'sqrt.spending.CC'</li>\n",
       "\t<li>'sqrt.spending.AX'</li>\n",
       "\t<li>'sqrt.spending.last.three.months'</li>\n",
       "\t<li>'sqrt.spending.last.one.month'</li>\n",
       "\t<li>'sqrt.spending.last.six.months'</li>\n",
       "\t<li>'sqrt.spending.SPLY'</li>\n",
       "\t<li>'flag.spending.AM'</li>\n",
       "\t<li>'flag.spending.PS'</li>\n",
       "\t<li>'flag.spending.CC'</li>\n",
       "\t<li>'flag.spending.AX'</li>\n",
       "\t<li>'flag.spending.last.three.months'</li>\n",
       "\t<li>'flag.spending.last.one.month'</li>\n",
       "\t<li>'flag.spending.last.six.months'</li>\n",
       "\t<li>'flag.spending.SPLY'</li>\n",
       "\t<li>'ln.days.between.purchases'</li>\n",
       "\t<li>'ln...different.product.classes'</li>\n",
       "\t<li>'sqrt...coupons.used'</li>\n",
       "\t<li>'ln...individual.items.purchased'</li>\n",
       "\t<li>'ln.stores'</li>\n",
       "\t<li>'ln.lifetime.ave.time.betw.visits'</li>\n",
       "\t<li>'ln.product.uniformity'</li>\n",
       "\t<li>'sqrt.responded'</li>\n",
       "\t<li>'flag.returns'</li>\n",
       "\t<li>'flag.response.rate'</li>\n",
       "\t<li>'flag.markdown'</li>\n",
       "\t<li>'sqrt.spending.months.2.3'</li>\n",
       "\t<li>'sqrt.spending.months.4.5.6'</li>\n",
       "\t<li>'flag.spending.months.4.5.6'</li>\n",
       "\t<li>'flag.spending.months.2.3'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'HHKEY'\n",
       "\\item 'ZIP\\_CODE'\n",
       "\\item 'REC'\n",
       "\\item 'FRE'\n",
       "\\item 'MON'\n",
       "\\item 'CC\\_CARD'\n",
       "\\item 'AVRG'\n",
       "\\item 'PC\\_CALC20'\n",
       "\\item 'PSWEATERS'\n",
       "\\item 'PKNIT\\_TOPS'\n",
       "\\item 'PKNIT\\_DRES'\n",
       "\\item 'PBLOUSES'\n",
       "\\item 'PJACKETS'\n",
       "\\item 'PCAR\\_PNTS'\n",
       "\\item 'PCAS\\_PNTS'\n",
       "\\item 'PSHIRTS'\n",
       "\\item 'PDRESSES'\n",
       "\\item 'PSUITS'\n",
       "\\item 'POUTERWEAR'\n",
       "\\item 'PJEWELRY'\n",
       "\\item 'PFASHION'\n",
       "\\item 'PLEGWEAR'\n",
       "\\item 'PCOLLSPND'\n",
       "\\item 'AMSPEND'\n",
       "\\item 'PSSPEND'\n",
       "\\item 'CCSPEND'\n",
       "\\item 'AXSPEND'\n",
       "\\item 'TMONSPEND'\n",
       "\\item 'OMONSPEND'\n",
       "\\item 'SMONSPEND'\n",
       "\\item 'PREVPD'\n",
       "\\item 'GMP'\n",
       "\\item 'PROMOS'\n",
       "\\item 'DAYS'\n",
       "\\item 'FREDAYS'\n",
       "\\item 'MARKDOWN'\n",
       "\\item 'CLASSES'\n",
       "\\item 'COUPONS'\n",
       "\\item 'STYLES'\n",
       "\\item 'STORES'\n",
       "\\item 'STORELOY'\n",
       "\\item 'VALPHON'\n",
       "\\item 'WEB'\n",
       "\\item 'MAILED'\n",
       "\\item 'RESPONDED'\n",
       "\\item 'RESPONSERATE'\n",
       "\\item 'HI'\n",
       "\\item 'LTFREDAY'\n",
       "\\item 'CLUSTYPE'\n",
       "\\item 'PERCRET'\n",
       "\\item 'RESP'\n",
       "\\item 'Tot\\_Spend'\n",
       "\\item 'Sales.per.Visit'\n",
       "\\item 'Spending\\_Month\\_2\\_3'\n",
       "\\item 'Spending\\_Month\\_4\\_5\\_6'\n",
       "\\item 'bc.purchase.visits'\n",
       "\\item 'ln.total.net.sales'\n",
       "\\item 'ln\\_ave.spending.per.visit'\n",
       "\\item 'sqrt.sweaters'\n",
       "\\item 'sqrt.knit.tops'\n",
       "\\item 'sqrt.knit.dresses'\n",
       "\\item 'sqrt.blouses'\n",
       "\\item 'sqrt.jackets'\n",
       "\\item 'sqrt.career.pants'\n",
       "\\item 'sqrt.casual.pants'\n",
       "\\item 'sqrt.shirts'\n",
       "\\item 'sqrt.dresses'\n",
       "\\item 'sqrt.suits'\n",
       "\\item 'sqrt.outerwear'\n",
       "\\item 'sqrt.jewelry'\n",
       "\\item 'sqrt.fashion'\n",
       "\\item 'sqrt.legwear'\n",
       "\\item 'sqrt.collectibles'\n",
       "\\item 'flag.sweaters'\n",
       "\\item 'flag.knit.tops'\n",
       "\\item 'flag.knit.dresses'\n",
       "\\item 'flag.blouses'\n",
       "\\item 'flag.jackets'\n",
       "\\item 'flag.career.pants'\n",
       "\\item 'flag.casual.pants'\n",
       "\\item 'flag.shirts'\n",
       "\\item 'flag.dresses'\n",
       "\\item 'flag.suits'\n",
       "\\item 'flag.outerwear'\n",
       "\\item 'flag.jewelry'\n",
       "\\item 'flag.fashion'\n",
       "\\item 'flag.legwear'\n",
       "\\item 'flag.collectibles'\n",
       "\\item 'sqrt.spending.AM'\n",
       "\\item 'sqrt.spending.PS'\n",
       "\\item 'sqrt.spending.CC'\n",
       "\\item 'sqrt.spending.AX'\n",
       "\\item 'sqrt.spending.last.three.months'\n",
       "\\item 'sqrt.spending.last.one.month'\n",
       "\\item 'sqrt.spending.last.six.months'\n",
       "\\item 'sqrt.spending.SPLY'\n",
       "\\item 'flag.spending.AM'\n",
       "\\item 'flag.spending.PS'\n",
       "\\item 'flag.spending.CC'\n",
       "\\item 'flag.spending.AX'\n",
       "\\item 'flag.spending.last.three.months'\n",
       "\\item 'flag.spending.last.one.month'\n",
       "\\item 'flag.spending.last.six.months'\n",
       "\\item 'flag.spending.SPLY'\n",
       "\\item 'ln.days.between.purchases'\n",
       "\\item 'ln...different.product.classes'\n",
       "\\item 'sqrt...coupons.used'\n",
       "\\item 'ln...individual.items.purchased'\n",
       "\\item 'ln.stores'\n",
       "\\item 'ln.lifetime.ave.time.betw.visits'\n",
       "\\item 'ln.product.uniformity'\n",
       "\\item 'sqrt.responded'\n",
       "\\item 'flag.returns'\n",
       "\\item 'flag.response.rate'\n",
       "\\item 'flag.markdown'\n",
       "\\item 'sqrt.spending.months.2.3'\n",
       "\\item 'sqrt.spending.months.4.5.6'\n",
       "\\item 'flag.spending.months.4.5.6'\n",
       "\\item 'flag.spending.months.2.3'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'HHKEY'\n",
       "2. 'ZIP_CODE'\n",
       "3. 'REC'\n",
       "4. 'FRE'\n",
       "5. 'MON'\n",
       "6. 'CC_CARD'\n",
       "7. 'AVRG'\n",
       "8. 'PC_CALC20'\n",
       "9. 'PSWEATERS'\n",
       "10. 'PKNIT_TOPS'\n",
       "11. 'PKNIT_DRES'\n",
       "12. 'PBLOUSES'\n",
       "13. 'PJACKETS'\n",
       "14. 'PCAR_PNTS'\n",
       "15. 'PCAS_PNTS'\n",
       "16. 'PSHIRTS'\n",
       "17. 'PDRESSES'\n",
       "18. 'PSUITS'\n",
       "19. 'POUTERWEAR'\n",
       "20. 'PJEWELRY'\n",
       "21. 'PFASHION'\n",
       "22. 'PLEGWEAR'\n",
       "23. 'PCOLLSPND'\n",
       "24. 'AMSPEND'\n",
       "25. 'PSSPEND'\n",
       "26. 'CCSPEND'\n",
       "27. 'AXSPEND'\n",
       "28. 'TMONSPEND'\n",
       "29. 'OMONSPEND'\n",
       "30. 'SMONSPEND'\n",
       "31. 'PREVPD'\n",
       "32. 'GMP'\n",
       "33. 'PROMOS'\n",
       "34. 'DAYS'\n",
       "35. 'FREDAYS'\n",
       "36. 'MARKDOWN'\n",
       "37. 'CLASSES'\n",
       "38. 'COUPONS'\n",
       "39. 'STYLES'\n",
       "40. 'STORES'\n",
       "41. 'STORELOY'\n",
       "42. 'VALPHON'\n",
       "43. 'WEB'\n",
       "44. 'MAILED'\n",
       "45. 'RESPONDED'\n",
       "46. 'RESPONSERATE'\n",
       "47. 'HI'\n",
       "48. 'LTFREDAY'\n",
       "49. 'CLUSTYPE'\n",
       "50. 'PERCRET'\n",
       "51. 'RESP'\n",
       "52. 'Tot_Spend'\n",
       "53. 'Sales.per.Visit'\n",
       "54. 'Spending_Month_2_3'\n",
       "55. 'Spending_Month_4_5_6'\n",
       "56. 'bc.purchase.visits'\n",
       "57. 'ln.total.net.sales'\n",
       "58. 'ln_ave.spending.per.visit'\n",
       "59. 'sqrt.sweaters'\n",
       "60. 'sqrt.knit.tops'\n",
       "61. 'sqrt.knit.dresses'\n",
       "62. 'sqrt.blouses'\n",
       "63. 'sqrt.jackets'\n",
       "64. 'sqrt.career.pants'\n",
       "65. 'sqrt.casual.pants'\n",
       "66. 'sqrt.shirts'\n",
       "67. 'sqrt.dresses'\n",
       "68. 'sqrt.suits'\n",
       "69. 'sqrt.outerwear'\n",
       "70. 'sqrt.jewelry'\n",
       "71. 'sqrt.fashion'\n",
       "72. 'sqrt.legwear'\n",
       "73. 'sqrt.collectibles'\n",
       "74. 'flag.sweaters'\n",
       "75. 'flag.knit.tops'\n",
       "76. 'flag.knit.dresses'\n",
       "77. 'flag.blouses'\n",
       "78. 'flag.jackets'\n",
       "79. 'flag.career.pants'\n",
       "80. 'flag.casual.pants'\n",
       "81. 'flag.shirts'\n",
       "82. 'flag.dresses'\n",
       "83. 'flag.suits'\n",
       "84. 'flag.outerwear'\n",
       "85. 'flag.jewelry'\n",
       "86. 'flag.fashion'\n",
       "87. 'flag.legwear'\n",
       "88. 'flag.collectibles'\n",
       "89. 'sqrt.spending.AM'\n",
       "90. 'sqrt.spending.PS'\n",
       "91. 'sqrt.spending.CC'\n",
       "92. 'sqrt.spending.AX'\n",
       "93. 'sqrt.spending.last.three.months'\n",
       "94. 'sqrt.spending.last.one.month'\n",
       "95. 'sqrt.spending.last.six.months'\n",
       "96. 'sqrt.spending.SPLY'\n",
       "97. 'flag.spending.AM'\n",
       "98. 'flag.spending.PS'\n",
       "99. 'flag.spending.CC'\n",
       "100. 'flag.spending.AX'\n",
       "101. 'flag.spending.last.three.months'\n",
       "102. 'flag.spending.last.one.month'\n",
       "103. 'flag.spending.last.six.months'\n",
       "104. 'flag.spending.SPLY'\n",
       "105. 'ln.days.between.purchases'\n",
       "106. 'ln...different.product.classes'\n",
       "107. 'sqrt...coupons.used'\n",
       "108. 'ln...individual.items.purchased'\n",
       "109. 'ln.stores'\n",
       "110. 'ln.lifetime.ave.time.betw.visits'\n",
       "111. 'ln.product.uniformity'\n",
       "112. 'sqrt.responded'\n",
       "113. 'flag.returns'\n",
       "114. 'flag.response.rate'\n",
       "115. 'flag.markdown'\n",
       "116. 'sqrt.spending.months.2.3'\n",
       "117. 'sqrt.spending.months.4.5.6'\n",
       "118. 'flag.spending.months.4.5.6'\n",
       "119. 'flag.spending.months.2.3'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] \"HHKEY\"                            \"ZIP_CODE\"                        \n",
       "  [3] \"REC\"                              \"FRE\"                             \n",
       "  [5] \"MON\"                              \"CC_CARD\"                         \n",
       "  [7] \"AVRG\"                             \"PC_CALC20\"                       \n",
       "  [9] \"PSWEATERS\"                        \"PKNIT_TOPS\"                      \n",
       " [11] \"PKNIT_DRES\"                       \"PBLOUSES\"                        \n",
       " [13] \"PJACKETS\"                         \"PCAR_PNTS\"                       \n",
       " [15] \"PCAS_PNTS\"                        \"PSHIRTS\"                         \n",
       " [17] \"PDRESSES\"                         \"PSUITS\"                          \n",
       " [19] \"POUTERWEAR\"                       \"PJEWELRY\"                        \n",
       " [21] \"PFASHION\"                         \"PLEGWEAR\"                        \n",
       " [23] \"PCOLLSPND\"                        \"AMSPEND\"                         \n",
       " [25] \"PSSPEND\"                          \"CCSPEND\"                         \n",
       " [27] \"AXSPEND\"                          \"TMONSPEND\"                       \n",
       " [29] \"OMONSPEND\"                        \"SMONSPEND\"                       \n",
       " [31] \"PREVPD\"                           \"GMP\"                             \n",
       " [33] \"PROMOS\"                           \"DAYS\"                            \n",
       " [35] \"FREDAYS\"                          \"MARKDOWN\"                        \n",
       " [37] \"CLASSES\"                          \"COUPONS\"                         \n",
       " [39] \"STYLES\"                           \"STORES\"                          \n",
       " [41] \"STORELOY\"                         \"VALPHON\"                         \n",
       " [43] \"WEB\"                              \"MAILED\"                          \n",
       " [45] \"RESPONDED\"                        \"RESPONSERATE\"                    \n",
       " [47] \"HI\"                               \"LTFREDAY\"                        \n",
       " [49] \"CLUSTYPE\"                         \"PERCRET\"                         \n",
       " [51] \"RESP\"                             \"Tot_Spend\"                       \n",
       " [53] \"Sales.per.Visit\"                  \"Spending_Month_2_3\"              \n",
       " [55] \"Spending_Month_4_5_6\"             \"bc.purchase.visits\"              \n",
       " [57] \"ln.total.net.sales\"               \"ln_ave.spending.per.visit\"       \n",
       " [59] \"sqrt.sweaters\"                    \"sqrt.knit.tops\"                  \n",
       " [61] \"sqrt.knit.dresses\"                \"sqrt.blouses\"                    \n",
       " [63] \"sqrt.jackets\"                     \"sqrt.career.pants\"               \n",
       " [65] \"sqrt.casual.pants\"                \"sqrt.shirts\"                     \n",
       " [67] \"sqrt.dresses\"                     \"sqrt.suits\"                      \n",
       " [69] \"sqrt.outerwear\"                   \"sqrt.jewelry\"                    \n",
       " [71] \"sqrt.fashion\"                     \"sqrt.legwear\"                    \n",
       " [73] \"sqrt.collectibles\"                \"flag.sweaters\"                   \n",
       " [75] \"flag.knit.tops\"                   \"flag.knit.dresses\"               \n",
       " [77] \"flag.blouses\"                     \"flag.jackets\"                    \n",
       " [79] \"flag.career.pants\"                \"flag.casual.pants\"               \n",
       " [81] \"flag.shirts\"                      \"flag.dresses\"                    \n",
       " [83] \"flag.suits\"                       \"flag.outerwear\"                  \n",
       " [85] \"flag.jewelry\"                     \"flag.fashion\"                    \n",
       " [87] \"flag.legwear\"                     \"flag.collectibles\"               \n",
       " [89] \"sqrt.spending.AM\"                 \"sqrt.spending.PS\"                \n",
       " [91] \"sqrt.spending.CC\"                 \"sqrt.spending.AX\"                \n",
       " [93] \"sqrt.spending.last.three.months\"  \"sqrt.spending.last.one.month\"    \n",
       " [95] \"sqrt.spending.last.six.months\"    \"sqrt.spending.SPLY\"              \n",
       " [97] \"flag.spending.AM\"                 \"flag.spending.PS\"                \n",
       " [99] \"flag.spending.CC\"                 \"flag.spending.AX\"                \n",
       "[101] \"flag.spending.last.three.months\"  \"flag.spending.last.one.month\"    \n",
       "[103] \"flag.spending.last.six.months\"    \"flag.spending.SPLY\"              \n",
       "[105] \"ln.days.between.purchases\"        \"ln...different.product.classes\"  \n",
       "[107] \"sqrt...coupons.used\"              \"ln...individual.items.purchased\" \n",
       "[109] \"ln.stores\"                        \"ln.lifetime.ave.time.betw.visits\"\n",
       "[111] \"ln.product.uniformity\"            \"sqrt.responded\"                  \n",
       "[113] \"flag.returns\"                     \"flag.response.rate\"              \n",
       "[115] \"flag.markdown\"                    \"sqrt.spending.months.2.3\"        \n",
       "[117] \"sqrt.spending.months.4.5.6\"       \"flag.spending.months.4.5.6\"      \n",
       "[119] \"flag.spending.months.2.3\"        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# variables\n",
    "colnames(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"VALPHON\"\n",
      "[1] \"flag.sweaters\"\n",
      "[1] \"flag.knit.tops\"\n",
      "[1] \"flag.knit.dresses\"\n",
      "[1] \"flag.blouses\"\n",
      "[1] \"flag.jackets\"\n",
      "[1] \"flag.career.pants\"\n",
      "[1] \"flag.casual.pants\"\n",
      "[1] \"flag.shirts\"\n",
      "[1] \"flag.dresses\"\n",
      "[1] \"flag.suits\"\n",
      "[1] \"flag.outerwear\"\n",
      "[1] \"flag.jewelry\"\n",
      "[1] \"flag.fashion\"\n",
      "[1] \"flag.legwear\"\n",
      "[1] \"flag.collectibles\"\n",
      "[1] \"flag.spending.AM\"\n",
      "[1] \"flag.spending.PS\"\n",
      "[1] \"flag.spending.CC\"\n",
      "[1] \"flag.spending.AX\"\n",
      "[1] \"flag.spending.last.three.months\"\n",
      "[1] \"flag.spending.last.one.month\"\n",
      "[1] \"flag.spending.last.six.months\"\n",
      "[1] \"flag.spending.SPLY\"\n",
      "[1] \"flag.returns\"\n",
      "[1] \"flag.response.rate\"\n",
      "[1] \"flag.markdown\"\n",
      "[1] \"flag.spending.months.4.5.6\"\n",
      "[1] \"flag.spending.months.2.3\"\n"
     ]
    }
   ],
   "source": [
    "# check non-numeric columns\n",
    "for( k in colnames(df) ){\n",
    "    i = class( df[, k] )\n",
    "    if( (i != \"numeric\") && (i != \"integer\") ){\n",
    "        print( k )\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the string value of Y to numeric 1.0\n",
    "vp = rep(0.0, dim(df)[1])\n",
    "vp[df$VALPHON==\"Y\"] = 1.0\n",
    "df$VALPHON = vp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"true/yes\" the first level of the factor:\n",
    "df$RESP[df$RESP == 1] = \"Yes\"\n",
    "df$RESP[df$RESP == 0] = \"No\" \n",
    "df$RESP = factor(df$RESP, levels=c(\"Yes\",\"No\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Yes   No \n",
      " 388 2231 \n",
      "\n",
      "      Yes        No \n",
      "0.1481481 0.8518519 \n"
     ]
    }
   ],
   "source": [
    "# check balance\n",
    "print(table(df$RESP))\n",
    "print(table(df$RESP) / sum(table(df$RESP)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Dropping    27 features due to zero variance from   119 (  0.2269 fraction)\"\n",
      "[1] \"Features dropped:\"\n",
      " [1] \"PKNIT_DRES\"        \"PJACKETS\"          \"PCAR_PNTS\"        \n",
      " [4] \"PCAS_PNTS\"         \"PSHIRTS\"           \"PDRESSES\"         \n",
      " [7] \"PSUITS\"            \"POUTERWEAR\"        \"PJEWELRY\"         \n",
      "[10] \"PFASHION\"          \"PCOLLSPND\"         \"AMSPEND\"          \n",
      "[13] \"WEB\"               \"PERCRET\"           \"sqrt.knit.tops\"   \n",
      "[16] \"sqrt.blouses\"      \"sqrt.jackets\"      \"sqrt.career.pants\"\n",
      "[19] \"sqrt.casual.pants\" \"sqrt.shirts\"       \"sqrt.dresses\"     \n",
      "[22] \"sqrt.suits\"        \"sqrt.outerwear\"    \"sqrt.jewelry\"     \n",
      "[25] \"sqrt.legwear\"      \"flag.collectibles\" \"flag.spending.PS\" \n"
     ]
    }
   ],
   "source": [
    "# check if any zero variance predictors in the features\n",
    "cols_0 = nearZeroVar(df[,-51] )\n",
    "colname = colnames(df)\n",
    "print(sprintf(\"Dropping %5d features due to zero variance from %5d (%8.4f fraction)\", \n",
    "              length(cols_0), length(colname), length(cols_0)/length(colname)) )\n",
    "print(\"Features dropped:\" )\n",
    "print(colname[cols_0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review:\n",
    "- dataset size: 2619 x 119\n",
    "- datatypes: integer, numeric, logical, factor\n",
    "- VALPHON was non-numeric so was converted to 1 0\n",
    "- factor of RESP is target, and its 1 and 0 were turned to Yes and No\n",
    "    - ~15% Yes, ~85% No\n",
    "- the nonzero identical values were dropped, which was about 23%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models:\n",
    "- Random Forest: method=\"rf\"\n",
    "- Flexible Discriminant Analysis: method=\"fda\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test set\n",
    "set.seed(24)  # this makes the example exactly reproducible\n",
    "split = createDataPartition(df$VALPHON, p=0.7 )[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        0         1 \n",
      "0.2311887 0.7688113 \n",
      "\n",
      "       0        1 \n",
      "0.211465 0.788535 \n"
     ]
    }
   ],
   "source": [
    "# validate by seeing fraction of train test sets of p=0.7 and p=0.3\n",
    "tt_split = table(df$VALPHON[split])\n",
    "print(tt_split/sum(tt_split))\n",
    "tt_not_split = table(df$VALPHON[-split])\n",
    "print(tt_not_split/sum(tt_not_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and other sets\n",
    "training = df[split,]\n",
    "other = df[-split,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split other into evaluation and test set\n",
    "split2 = createDataPartition(other$VALPHON, p=1./3)[[1]]\n",
    "evaluation = other[split2,]\n",
    "testing = other[-split2,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build classification models (following books examples)\n",
    "# functions for performance measures\n",
    "fiveStats = function(...) c(twoClassSummary(...), defaultSummary(...))\n",
    "fourStats = function(data, lev=levels(data$obs), model=NULL){\n",
    "    accKapp = postResample(data[, \"pred\"], data[, \"obs\"])\n",
    "    out = c(accKapp,\n",
    "        sensitivity(data[, \"pred\"], data[, \"obs\"], lev[1]),\n",
    "        specificity(data[, \"pred\"], data[, \"obs\"], lev[2]))\n",
    "    names(out)[3:4] = c(\"Sens\", \"Spec\")\n",
    "    out\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$method</dt>\n",
       "\t\t<dd>'cv'</dd>\n",
       "\t<dt>$number</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>$repeats</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "\t<dt>$search</dt>\n",
       "\t\t<dd>'grid'</dd>\n",
       "\t<dt>$p</dt>\n",
       "\t\t<dd>0.75</dd>\n",
       "\t<dt>$initialWindow</dt>\n",
       "\t\t<dd>NULL</dd>\n",
       "\t<dt>$horizon</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$fixedWindow</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$skip</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$verboseIter</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$returnData</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$returnResamp</dt>\n",
       "\t\t<dd>'final'</dd>\n",
       "\t<dt>$savePredictions</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$classProbs</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "\t<dt>$summaryFunction</dt>\n",
       "\t\t<dd><pre class=language-r><code>function (...) \n",
       "c(twoClassSummary(...), defaultSummary(...))</code></pre></dd>\n",
       "\t<dt>$selectionFunction</dt>\n",
       "\t\t<dd>'best'</dd>\n",
       "\t<dt>$preProcOptions</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$thresh</dt>\n",
       "\t\t<dd>0.95</dd>\n",
       "\t<dt>$ICAcomp</dt>\n",
       "\t\t<dd>3</dd>\n",
       "\t<dt>$k</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>$freqCut</dt>\n",
       "\t\t<dd>19</dd>\n",
       "\t<dt>$uniqueCut</dt>\n",
       "\t\t<dd>10</dd>\n",
       "\t<dt>$cutoff</dt>\n",
       "\t\t<dd>0.9</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$sampling</dt>\n",
       "\t\t<dd>NULL</dd>\n",
       "\t<dt>$index</dt>\n",
       "\t\t<dd>NULL</dd>\n",
       "\t<dt>$indexOut</dt>\n",
       "\t\t<dd>NULL</dd>\n",
       "\t<dt>$indexFinal</dt>\n",
       "\t\t<dd>NULL</dd>\n",
       "\t<dt>$timingSamps</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>$predictionBounds</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>FALSE</li>\n",
       "\t<li>FALSE</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$seeds</dt>\n",
       "\t\t<dd>&lt;NA&gt;</dd>\n",
       "\t<dt>$adaptive</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$min</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>$alpha</dt>\n",
       "\t\t<dd>0.05</dd>\n",
       "\t<dt>$method</dt>\n",
       "\t\t<dd>'gls'</dd>\n",
       "\t<dt>$complete</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$trim</dt>\n",
       "\t\t<dd>FALSE</dd>\n",
       "\t<dt>$allowParallel</dt>\n",
       "\t\t<dd>TRUE</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$method] 'cv'\n",
       "\\item[\\$number] 5\n",
       "\\item[\\$repeats] <NA>\n",
       "\\item[\\$search] 'grid'\n",
       "\\item[\\$p] 0.75\n",
       "\\item[\\$initialWindow] NULL\n",
       "\\item[\\$horizon] 1\n",
       "\\item[\\$fixedWindow] TRUE\n",
       "\\item[\\$skip] 0\n",
       "\\item[\\$verboseIter] TRUE\n",
       "\\item[\\$returnData] TRUE\n",
       "\\item[\\$returnResamp] 'final'\n",
       "\\item[\\$savePredictions] FALSE\n",
       "\\item[\\$classProbs] TRUE\n",
       "\\item[\\$summaryFunction] \\begin{minted}{r}\n",
       "function (...) \n",
       "c(twoClassSummary(...), defaultSummary(...))\n",
       "\\end{minted}\n",
       "\\item[\\$selectionFunction] 'best'\n",
       "\\item[\\$preProcOptions] \\begin{description}\n",
       "\\item[\\$thresh] 0.95\n",
       "\\item[\\$ICAcomp] 3\n",
       "\\item[\\$k] 5\n",
       "\\item[\\$freqCut] 19\n",
       "\\item[\\$uniqueCut] 10\n",
       "\\item[\\$cutoff] 0.9\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$sampling] NULL\n",
       "\\item[\\$index] NULL\n",
       "\\item[\\$indexOut] NULL\n",
       "\\item[\\$indexFinal] NULL\n",
       "\\item[\\$timingSamps] 0\n",
       "\\item[\\$predictionBounds] \\begin{enumerate*}\n",
       "\\item FALSE\n",
       "\\item FALSE\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$seeds] <NA>\n",
       "\\item[\\$adaptive] \\begin{description}\n",
       "\\item[\\$min] 5\n",
       "\\item[\\$alpha] 0.05\n",
       "\\item[\\$method] 'gls'\n",
       "\\item[\\$complete] TRUE\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$trim] FALSE\n",
       "\\item[\\$allowParallel] TRUE\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$method\n",
       ":   'cv'\n",
       "$number\n",
       ":   5\n",
       "$repeats\n",
       ":   &lt;NA&gt;\n",
       "$search\n",
       ":   'grid'\n",
       "$p\n",
       ":   0.75\n",
       "$initialWindow\n",
       ":   NULL\n",
       "$horizon\n",
       ":   1\n",
       "$fixedWindow\n",
       ":   TRUE\n",
       "$skip\n",
       ":   0\n",
       "$verboseIter\n",
       ":   TRUE\n",
       "$returnData\n",
       ":   TRUE\n",
       "$returnResamp\n",
       ":   'final'\n",
       "$savePredictions\n",
       ":   FALSE\n",
       "$classProbs\n",
       ":   TRUE\n",
       "$summaryFunction\n",
       ":   ```r\n",
       "function (...) \n",
       "c(twoClassSummary(...), defaultSummary(...))\n",
       "```\n",
       "$selectionFunction\n",
       ":   'best'\n",
       "$preProcOptions\n",
       ":   $thresh\n",
       ":   0.95\n",
       "$ICAcomp\n",
       ":   3\n",
       "$k\n",
       ":   5\n",
       "$freqCut\n",
       ":   19\n",
       "$uniqueCut\n",
       ":   10\n",
       "$cutoff\n",
       ":   0.9\n",
       "\n",
       "\n",
       "\n",
       "$sampling\n",
       ":   NULL\n",
       "$index\n",
       ":   NULL\n",
       "$indexOut\n",
       ":   NULL\n",
       "$indexFinal\n",
       ":   NULL\n",
       "$timingSamps\n",
       ":   0\n",
       "$predictionBounds\n",
       ":   1. FALSE\n",
       "2. FALSE\n",
       "\n",
       "\n",
       "\n",
       "$seeds\n",
       ":   &lt;NA&gt;\n",
       "$adaptive\n",
       ":   $min\n",
       ":   5\n",
       "$alpha\n",
       ":   0.05\n",
       "$method\n",
       ":   'gls'\n",
       "$complete\n",
       ":   TRUE\n",
       "\n",
       "\n",
       "\n",
       "$trim\n",
       ":   FALSE\n",
       "$allowParallel\n",
       ":   TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$method\n",
       "[1] \"cv\"\n",
       "\n",
       "$number\n",
       "[1] 5\n",
       "\n",
       "$repeats\n",
       "[1] NA\n",
       "\n",
       "$search\n",
       "[1] \"grid\"\n",
       "\n",
       "$p\n",
       "[1] 0.75\n",
       "\n",
       "$initialWindow\n",
       "NULL\n",
       "\n",
       "$horizon\n",
       "[1] 1\n",
       "\n",
       "$fixedWindow\n",
       "[1] TRUE\n",
       "\n",
       "$skip\n",
       "[1] 0\n",
       "\n",
       "$verboseIter\n",
       "[1] TRUE\n",
       "\n",
       "$returnData\n",
       "[1] TRUE\n",
       "\n",
       "$returnResamp\n",
       "[1] \"final\"\n",
       "\n",
       "$savePredictions\n",
       "[1] FALSE\n",
       "\n",
       "$classProbs\n",
       "[1] TRUE\n",
       "\n",
       "$summaryFunction\n",
       "function(...) c(twoClassSummary(...), defaultSummary(...))\n",
       "\n",
       "$selectionFunction\n",
       "[1] \"best\"\n",
       "\n",
       "$preProcOptions\n",
       "$preProcOptions$thresh\n",
       "[1] 0.95\n",
       "\n",
       "$preProcOptions$ICAcomp\n",
       "[1] 3\n",
       "\n",
       "$preProcOptions$k\n",
       "[1] 5\n",
       "\n",
       "$preProcOptions$freqCut\n",
       "[1] 19\n",
       "\n",
       "$preProcOptions$uniqueCut\n",
       "[1] 10\n",
       "\n",
       "$preProcOptions$cutoff\n",
       "[1] 0.9\n",
       "\n",
       "\n",
       "$sampling\n",
       "NULL\n",
       "\n",
       "$index\n",
       "NULL\n",
       "\n",
       "$indexOut\n",
       "NULL\n",
       "\n",
       "$indexFinal\n",
       "NULL\n",
       "\n",
       "$timingSamps\n",
       "[1] 0\n",
       "\n",
       "$predictionBounds\n",
       "[1] FALSE FALSE\n",
       "\n",
       "$seeds\n",
       "[1] NA\n",
       "\n",
       "$adaptive\n",
       "$adaptive$min\n",
       "[1] 5\n",
       "\n",
       "$adaptive$alpha\n",
       "[1] 0.05\n",
       "\n",
       "$adaptive$method\n",
       "[1] \"gls\"\n",
       "\n",
       "$adaptive$complete\n",
       "[1] TRUE\n",
       "\n",
       "\n",
       "$trim\n",
       "[1] FALSE\n",
       "\n",
       "$allowParallel\n",
       "[1] TRUE\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# control parameters for the algorithm used by the models\n",
    "ctrl = trainControl(method=\"cv\", number=5, classProbs=TRUE, summaryFunction=fiveStats, verboseIter=TRUE )\n",
    "ctrl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold1: mtry=  2 \n",
      "- Fold1: mtry=  2 \n",
      "+ Fold1: mtry= 31 \n",
      "- Fold1: mtry= 31 \n",
      "+ Fold1: mtry= 60 \n",
      "- Fold1: mtry= 60 \n",
      "+ Fold1: mtry= 89 \n",
      "- Fold1: mtry= 89 \n",
      "+ Fold1: mtry=118 \n",
      "- Fold1: mtry=118 \n",
      "+ Fold2: mtry=  2 \n",
      "- Fold2: mtry=  2 \n",
      "+ Fold2: mtry= 31 \n",
      "- Fold2: mtry= 31 \n",
      "+ Fold2: mtry= 60 \n",
      "- Fold2: mtry= 60 \n",
      "+ Fold2: mtry= 89 \n",
      "- Fold2: mtry= 89 \n",
      "+ Fold2: mtry=118 \n",
      "- Fold2: mtry=118 \n",
      "+ Fold3: mtry=  2 \n",
      "- Fold3: mtry=  2 \n",
      "+ Fold3: mtry= 31 \n",
      "- Fold3: mtry= 31 \n",
      "+ Fold3: mtry= 60 \n",
      "- Fold3: mtry= 60 \n",
      "+ Fold3: mtry= 89 \n",
      "- Fold3: mtry= 89 \n",
      "+ Fold3: mtry=118 \n",
      "- Fold3: mtry=118 \n",
      "+ Fold4: mtry=  2 \n",
      "- Fold4: mtry=  2 \n",
      "+ Fold4: mtry= 31 \n",
      "- Fold4: mtry= 31 \n",
      "+ Fold4: mtry= 60 \n",
      "- Fold4: mtry= 60 \n",
      "+ Fold4: mtry= 89 \n",
      "- Fold4: mtry= 89 \n",
      "+ Fold4: mtry=118 \n",
      "- Fold4: mtry=118 \n",
      "+ Fold5: mtry=  2 \n",
      "- Fold5: mtry=  2 \n",
      "+ Fold5: mtry= 31 \n",
      "- Fold5: mtry= 31 \n",
      "+ Fold5: mtry= 60 \n",
      "- Fold5: mtry= 60 \n",
      "+ Fold5: mtry= 89 \n",
      "- Fold5: mtry= 89 \n",
      "+ Fold5: mtry=118 \n",
      "- Fold5: mtry=118 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 60 on full training set\n"
     ]
    }
   ],
   "source": [
    "# RF model with ntree=500 and tuneLength=5\n",
    "set.seed(123)\n",
    "rfFit = train( RESP ~ ., data=training, method=\"rf\", trControl=ctrl, ntree=500, tuneLength=5, metric=\"ROC\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/ankur/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'fda' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\ankur\\AppData\\Local\\Temp\\RtmpI7YzT2\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/ankur/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'earth' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\ankur\\AppData\\Local\\Temp\\RtmpI7YzT2\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/ankur/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'mda' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\ankur\\AppData\\Local\\Temp\\RtmpI7YzT2\\downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "# for FDA\n",
    "install.packages(\"fda\")\n",
    "install.packages(\"earth\")\n",
    "install.packages(\"mda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: splines\n",
      "Loading required package: Matrix\n",
      "\n",
      "Attaching package: 'fda'\n",
      "\n",
      "The following object is masked from 'package:graphics':\n",
      "\n",
      "    matplot\n",
      "\n",
      "Loading required package: Formula\n",
      "Loading required package: plotmo\n",
      "Loading required package: plotrix\n",
      "Loading required package: TeachingDemos\n",
      "Loading required package: class\n",
      "Loaded mda 0.4-10\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold1: nprune= 2, degree=1 \n",
      "- Fold1: nprune= 2, degree=1 \n",
      "+ Fold1: nprune= 3, degree=1 \n",
      "- Fold1: nprune= 3, degree=1 \n",
      "+ Fold1: nprune= 5, degree=1 \n",
      "- Fold1: nprune= 5, degree=1 \n",
      "+ Fold1: nprune= 7, degree=1 \n",
      "- Fold1: nprune= 7, degree=1 \n",
      "+ Fold1: nprune= 8, degree=1 \n",
      "- Fold1: nprune= 8, degree=1 \n",
      "+ Fold1: nprune=10, degree=1 \n",
      "- Fold1: nprune=10, degree=1 \n",
      "+ Fold1: nprune=12, degree=1 \n",
      "- Fold1: nprune=12, degree=1 \n",
      "+ Fold1: nprune=13, degree=1 \n",
      "- Fold1: nprune=13, degree=1 \n",
      "+ Fold1: nprune=15, degree=1 \n",
      "- Fold1: nprune=15, degree=1 \n",
      "+ Fold1: nprune=17, degree=1 \n",
      "- Fold1: nprune=17, degree=1 \n",
      "+ Fold2: nprune= 2, degree=1 \n",
      "- Fold2: nprune= 2, degree=1 \n",
      "+ Fold2: nprune= 3, degree=1 \n",
      "- Fold2: nprune= 3, degree=1 \n",
      "+ Fold2: nprune= 5, degree=1 \n",
      "- Fold2: nprune= 5, degree=1 \n",
      "+ Fold2: nprune= 7, degree=1 \n",
      "- Fold2: nprune= 7, degree=1 \n",
      "+ Fold2: nprune= 8, degree=1 \n",
      "- Fold2: nprune= 8, degree=1 \n",
      "+ Fold2: nprune=10, degree=1 \n",
      "- Fold2: nprune=10, degree=1 \n",
      "+ Fold2: nprune=12, degree=1 \n",
      "- Fold2: nprune=12, degree=1 \n",
      "+ Fold2: nprune=13, degree=1 \n",
      "- Fold2: nprune=13, degree=1 \n",
      "+ Fold2: nprune=15, degree=1 \n",
      "- Fold2: nprune=15, degree=1 \n",
      "+ Fold2: nprune=17, degree=1 \n",
      "- Fold2: nprune=17, degree=1 \n",
      "+ Fold3: nprune= 2, degree=1 \n",
      "- Fold3: nprune= 2, degree=1 \n",
      "+ Fold3: nprune= 3, degree=1 \n",
      "- Fold3: nprune= 3, degree=1 \n",
      "+ Fold3: nprune= 5, degree=1 \n",
      "- Fold3: nprune= 5, degree=1 \n",
      "+ Fold3: nprune= 7, degree=1 \n",
      "- Fold3: nprune= 7, degree=1 \n",
      "+ Fold3: nprune= 8, degree=1 \n",
      "- Fold3: nprune= 8, degree=1 \n",
      "+ Fold3: nprune=10, degree=1 \n",
      "- Fold3: nprune=10, degree=1 \n",
      "+ Fold3: nprune=12, degree=1 \n",
      "- Fold3: nprune=12, degree=1 \n",
      "+ Fold3: nprune=13, degree=1 \n",
      "- Fold3: nprune=13, degree=1 \n",
      "+ Fold3: nprune=15, degree=1 \n",
      "- Fold3: nprune=15, degree=1 \n",
      "+ Fold3: nprune=17, degree=1 \n",
      "- Fold3: nprune=17, degree=1 \n",
      "+ Fold4: nprune= 2, degree=1 \n",
      "- Fold4: nprune= 2, degree=1 \n",
      "+ Fold4: nprune= 3, degree=1 \n",
      "- Fold4: nprune= 3, degree=1 \n",
      "+ Fold4: nprune= 5, degree=1 \n",
      "- Fold4: nprune= 5, degree=1 \n",
      "+ Fold4: nprune= 7, degree=1 \n",
      "- Fold4: nprune= 7, degree=1 \n",
      "+ Fold4: nprune= 8, degree=1 \n",
      "- Fold4: nprune= 8, degree=1 \n",
      "+ Fold4: nprune=10, degree=1 \n",
      "- Fold4: nprune=10, degree=1 \n",
      "+ Fold4: nprune=12, degree=1 \n",
      "- Fold4: nprune=12, degree=1 \n",
      "+ Fold4: nprune=13, degree=1 \n",
      "- Fold4: nprune=13, degree=1 \n",
      "+ Fold4: nprune=15, degree=1 \n",
      "- Fold4: nprune=15, degree=1 \n",
      "+ Fold4: nprune=17, degree=1 \n",
      "- Fold4: nprune=17, degree=1 \n",
      "+ Fold5: nprune= 2, degree=1 \n",
      "- Fold5: nprune= 2, degree=1 \n",
      "+ Fold5: nprune= 3, degree=1 \n",
      "- Fold5: nprune= 3, degree=1 \n",
      "+ Fold5: nprune= 5, degree=1 \n",
      "- Fold5: nprune= 5, degree=1 \n",
      "+ Fold5: nprune= 7, degree=1 \n",
      "- Fold5: nprune= 7, degree=1 \n",
      "+ Fold5: nprune= 8, degree=1 \n",
      "- Fold5: nprune= 8, degree=1 \n",
      "+ Fold5: nprune=10, degree=1 \n",
      "- Fold5: nprune=10, degree=1 \n",
      "+ Fold5: nprune=12, degree=1 \n",
      "- Fold5: nprune=12, degree=1 \n",
      "+ Fold5: nprune=13, degree=1 \n",
      "- Fold5: nprune=13, degree=1 \n",
      "+ Fold5: nprune=15, degree=1 \n",
      "- Fold5: nprune=15, degree=1 \n",
      "+ Fold5: nprune=17, degree=1 \n",
      "- Fold5: nprune=17, degree=1 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting degree = 1, nprune = 3 on full training set\n"
     ]
    }
   ],
   "source": [
    "# FDA model with tuneLength=10 and the control parameters\n",
    "library(fda)\n",
    "library(earth)\n",
    "library(mda)\n",
    "set.seed(123)\n",
    "fdaFit = train( RESP ~ ., data=training, method=\"fda\", tuneLength=10, trControl=ctrl, metric=\"ROC\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AUC      Spec      Sens\n",
      "RF  0.8239196 0.9641456 0.2350842\n",
      "FDA 0.8446561 0.9404727 0.3674074\n"
     ]
    }
   ],
   "source": [
    "# compare estimated sensitivity and specificity for methods on training set\n",
    "res = matrix( data=c( mean( rfFit$resample$ROC ), mean( rfFit$resample$Spec ), mean( rfFit$resample$Sens ),\n",
    "                      mean( fdaFit$resample$ROC ), mean( fdaFit$resample$Spec ), mean( fdaFit$resample$Sens ) ),\n",
    "    nrow=2, ncol=3, byrow=T )\n",
    "res = data.frame( res )\n",
    "rownames(res) = c(\"RF\", \"FDA\" )\n",
    "colnames(res) = c(\"AUC\", \"Spec\", \"Sens\" )\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true sensitivity and specificity on the evaluation set\n",
    "evalRes = data.frame( RESP = evaluation$RESP ) \n",
    "evalRes$RF = predict( rfFit, newdata=evaluation, type=\"prob\" )[,1]\n",
    "evalRes$FDA = predict( fdaFit, newdata=evaluation, type=\"prob\" )[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing package into 'C:/Users/ankur/Documents/R/win-library/3.6'\n",
      "(as 'lib' is unspecified)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "package 'pROC' successfully unpacked and MD5 sums checked\n",
      "\n",
      "The downloaded binary packages are in\n",
      "\tC:\\Users\\ankur\\AppData\\Local\\Temp\\RtmpI7YzT2\\downloaded_packages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Type 'citation(\"pROC\")' for a citation.\n",
      "\n",
      "Attaching package: 'pROC'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cov, smooth, var\n",
      "\n",
      "Setting direction: controls < cases\n",
      "Setting direction: controls < cases\n"
     ]
    }
   ],
   "source": [
    "# lift plots on the model classifiers\n",
    "install.packages(\"pROC\")\n",
    "library(pROC)\n",
    "rfROC = roc( evalRes$RESP, evalRes$RF, levels=rev( levels(evalRes$RESP) ) )\n",
    "FDAROC = roc( evalRes$RESP, evalRes$FDA, levels=rev( levels(evalRes$RESP) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAA/wBNTU1oaGh8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\nrkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC\n",
    "plot(rfROC, legacy.axes=TRUE, col=\"red\")\n",
    "plot(FDAROC, legacy.axes=TRUE, add=T, col=\"green\")\n",
    "legend( x=\"bottomright\", c(sprintf(\"RF (%f)\", rfROC$auc), sprintf(\"FDA (%f)\", FDAROC$auc)), \n",
    "       col=c(\"red\", \"green\"), lty=c(1,1,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Yes   No \n",
      "1562 1562 \n"
     ]
    }
   ],
   "source": [
    "# random upsampling to fix the group sizes to the largest group in the dataframe\n",
    "set.seed(111)\n",
    "upSampleTrain = upSample( x=training[,-51] , y=training$RESP, yname=\"RESP\" )\n",
    "print( table( upSampleTrain$RESP ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold1: mtry=  2 \n",
      "- Fold1: mtry=  2 \n",
      "+ Fold1: mtry= 31 \n",
      "- Fold1: mtry= 31 \n",
      "+ Fold1: mtry= 60 \n",
      "- Fold1: mtry= 60 \n",
      "+ Fold1: mtry= 89 \n",
      "- Fold1: mtry= 89 \n",
      "+ Fold1: mtry=118 \n",
      "- Fold1: mtry=118 \n",
      "+ Fold2: mtry=  2 \n",
      "- Fold2: mtry=  2 \n",
      "+ Fold2: mtry= 31 \n",
      "- Fold2: mtry= 31 \n",
      "+ Fold2: mtry= 60 \n",
      "- Fold2: mtry= 60 \n",
      "+ Fold2: mtry= 89 \n",
      "- Fold2: mtry= 89 \n",
      "+ Fold2: mtry=118 \n",
      "- Fold2: mtry=118 \n",
      "+ Fold3: mtry=  2 \n",
      "- Fold3: mtry=  2 \n",
      "+ Fold3: mtry= 31 \n",
      "- Fold3: mtry= 31 \n",
      "+ Fold3: mtry= 60 \n",
      "- Fold3: mtry= 60 \n",
      "+ Fold3: mtry= 89 \n",
      "- Fold3: mtry= 89 \n",
      "+ Fold3: mtry=118 \n",
      "- Fold3: mtry=118 \n",
      "+ Fold4: mtry=  2 \n",
      "- Fold4: mtry=  2 \n",
      "+ Fold4: mtry= 31 \n",
      "- Fold4: mtry= 31 \n",
      "+ Fold4: mtry= 60 \n",
      "- Fold4: mtry= 60 \n",
      "+ Fold4: mtry= 89 \n",
      "- Fold4: mtry= 89 \n",
      "+ Fold4: mtry=118 \n",
      "- Fold4: mtry=118 \n",
      "+ Fold5: mtry=  2 \n",
      "- Fold5: mtry=  2 \n",
      "+ Fold5: mtry= 31 \n",
      "- Fold5: mtry= 31 \n",
      "+ Fold5: mtry= 60 \n",
      "- Fold5: mtry= 60 \n",
      "+ Fold5: mtry= 89 \n",
      "- Fold5: mtry= 89 \n",
      "+ Fold5: mtry=118 \n",
      "- Fold5: mtry=118 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 31 on full training set\n"
     ]
    }
   ],
   "source": [
    "# same models with upSample dataframe\n",
    "# RF\n",
    "set.seed(123)\n",
    "rfFit_us = train( RESP ~ ., data=upSampleTrain, method=\"rf\", \n",
    "                 trControl=ctrl, ntree=500, tuneLength=5, metric=\"ROC\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold1: nprune= 2, degree=1 \n",
      "- Fold1: nprune= 2, degree=1 \n",
      "+ Fold1: nprune= 3, degree=1 \n",
      "- Fold1: nprune= 3, degree=1 \n",
      "+ Fold1: nprune= 5, degree=1 \n",
      "- Fold1: nprune= 5, degree=1 \n",
      "+ Fold1: nprune= 7, degree=1 \n",
      "- Fold1: nprune= 7, degree=1 \n",
      "+ Fold1: nprune= 8, degree=1 \n",
      "- Fold1: nprune= 8, degree=1 \n",
      "+ Fold1: nprune=10, degree=1 \n",
      "- Fold1: nprune=10, degree=1 \n",
      "+ Fold1: nprune=12, degree=1 \n",
      "- Fold1: nprune=12, degree=1 \n",
      "+ Fold1: nprune=13, degree=1 \n",
      "- Fold1: nprune=13, degree=1 \n",
      "+ Fold1: nprune=15, degree=1 \n",
      "- Fold1: nprune=15, degree=1 \n",
      "+ Fold1: nprune=17, degree=1 \n",
      "- Fold1: nprune=17, degree=1 \n",
      "+ Fold2: nprune= 2, degree=1 \n",
      "- Fold2: nprune= 2, degree=1 \n",
      "+ Fold2: nprune= 3, degree=1 \n",
      "- Fold2: nprune= 3, degree=1 \n",
      "+ Fold2: nprune= 5, degree=1 \n",
      "- Fold2: nprune= 5, degree=1 \n",
      "+ Fold2: nprune= 7, degree=1 \n",
      "- Fold2: nprune= 7, degree=1 \n",
      "+ Fold2: nprune= 8, degree=1 \n",
      "- Fold2: nprune= 8, degree=1 \n",
      "+ Fold2: nprune=10, degree=1 \n",
      "- Fold2: nprune=10, degree=1 \n",
      "+ Fold2: nprune=12, degree=1 \n",
      "- Fold2: nprune=12, degree=1 \n",
      "+ Fold2: nprune=13, degree=1 \n",
      "- Fold2: nprune=13, degree=1 \n",
      "+ Fold2: nprune=15, degree=1 \n",
      "- Fold2: nprune=15, degree=1 \n",
      "+ Fold2: nprune=17, degree=1 \n",
      "- Fold2: nprune=17, degree=1 \n",
      "+ Fold3: nprune= 2, degree=1 \n",
      "- Fold3: nprune= 2, degree=1 \n",
      "+ Fold3: nprune= 3, degree=1 \n",
      "- Fold3: nprune= 3, degree=1 \n",
      "+ Fold3: nprune= 5, degree=1 \n",
      "- Fold3: nprune= 5, degree=1 \n",
      "+ Fold3: nprune= 7, degree=1 \n",
      "- Fold3: nprune= 7, degree=1 \n",
      "+ Fold3: nprune= 8, degree=1 \n",
      "- Fold3: nprune= 8, degree=1 \n",
      "+ Fold3: nprune=10, degree=1 \n",
      "- Fold3: nprune=10, degree=1 \n",
      "+ Fold3: nprune=12, degree=1 \n",
      "- Fold3: nprune=12, degree=1 \n",
      "+ Fold3: nprune=13, degree=1 \n",
      "- Fold3: nprune=13, degree=1 \n",
      "+ Fold3: nprune=15, degree=1 \n",
      "- Fold3: nprune=15, degree=1 \n",
      "+ Fold3: nprune=17, degree=1 \n",
      "- Fold3: nprune=17, degree=1 \n",
      "+ Fold4: nprune= 2, degree=1 \n",
      "- Fold4: nprune= 2, degree=1 \n",
      "+ Fold4: nprune= 3, degree=1 \n",
      "- Fold4: nprune= 3, degree=1 \n",
      "+ Fold4: nprune= 5, degree=1 \n",
      "- Fold4: nprune= 5, degree=1 \n",
      "+ Fold4: nprune= 7, degree=1 \n",
      "- Fold4: nprune= 7, degree=1 \n",
      "+ Fold4: nprune= 8, degree=1 \n",
      "- Fold4: nprune= 8, degree=1 \n",
      "+ Fold4: nprune=10, degree=1 \n",
      "- Fold4: nprune=10, degree=1 \n",
      "+ Fold4: nprune=12, degree=1 \n",
      "- Fold4: nprune=12, degree=1 \n",
      "+ Fold4: nprune=13, degree=1 \n",
      "- Fold4: nprune=13, degree=1 \n",
      "+ Fold4: nprune=15, degree=1 \n",
      "- Fold4: nprune=15, degree=1 \n",
      "+ Fold4: nprune=17, degree=1 \n",
      "- Fold4: nprune=17, degree=1 \n",
      "+ Fold5: nprune= 2, degree=1 \n",
      "- Fold5: nprune= 2, degree=1 \n",
      "+ Fold5: nprune= 3, degree=1 \n",
      "- Fold5: nprune= 3, degree=1 \n",
      "+ Fold5: nprune= 5, degree=1 \n",
      "- Fold5: nprune= 5, degree=1 \n",
      "+ Fold5: nprune= 7, degree=1 \n",
      "- Fold5: nprune= 7, degree=1 \n",
      "+ Fold5: nprune= 8, degree=1 \n",
      "- Fold5: nprune= 8, degree=1 \n",
      "+ Fold5: nprune=10, degree=1 \n",
      "- Fold5: nprune=10, degree=1 \n",
      "+ Fold5: nprune=12, degree=1 \n",
      "- Fold5: nprune=12, degree=1 \n",
      "+ Fold5: nprune=13, degree=1 \n",
      "- Fold5: nprune=13, degree=1 \n",
      "+ Fold5: nprune=15, degree=1 \n",
      "- Fold5: nprune=15, degree=1 \n",
      "+ Fold5: nprune=17, degree=1 \n",
      "- Fold5: nprune=17, degree=1 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting degree = 1, nprune = 12 on full training set\n"
     ]
    }
   ],
   "source": [
    "# FDA\n",
    "set.seed(123)\n",
    "fdaFit_us = train( RESP ~ ., data=upSampleTrain, method=\"fda\", \n",
    "                  tuneLength=10, trControl=ctrl, metric=\"ROC\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in mean.default(rfFit_us$Eesample$Sens):\n",
      "\"argument is not numeric or logical: returning NA\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          AUC      Spec      Sens\n",
      "RF  0.9985238 0.9155075        NA\n",
      "FDA 0.8690034 0.7093553 0.8450807\n"
     ]
    }
   ],
   "source": [
    "# compare estimated sensitivity and specificity for methods on upSample training set\n",
    "res = matrix(data=c(mean(rfFit_us$resample$ROC), mean(rfFit_us$resample$Spec), mean(rfFit_us$Eesample$Sens),\n",
    "                    mean(fdaFit_us$resample$ROC), mean(fdaFit_us$resample$Spec), mean(fdaFit_us$resample$Sens)),\n",
    "             nrow=2, ncol=3, byrow=T )\n",
    "res = data.frame( res )\n",
    "rownames(res) = c(\"RF\", \"FDA\" )\n",
    "colnames(res) = c(\"AUC\", \"Spec\", \"Sens\" )\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true sensitivity and specificity for upScale sets on the evaluation set\n",
    "evalResults = data.frame( RESP = evaluation$RESP ) # put in the truth\n",
    "evalResults$RF = predict( rfFit_us, newdata=evaluation, type=\"prob\" )[,1]\n",
    "evalResults$FDA = predict( fdaFit_us, newdata=evaluation, type=\"prob\" )[,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting direction: controls < cases\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "roc.default(response = evalResults$RESP, predictor = evalResults$RF,     levels = rev(levels(evalResults$RESP)))\n",
      "\n",
      "Data: evalResults$RF in 223 controls (evalResults$RESP No) < 39 cases (evalResults$RESP Yes).\n",
      "Area under the curve: 0.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting direction: controls < cases\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Call:\n",
      "roc.default(response = evalResults$RESP, predictor = evalResults$FDA,     levels = rev(levels(evalResults$RESP)))\n",
      "\n",
      "Data: evalResults$FDA in 223 controls (evalResults$RESP No) < 39 cases (evalResults$RESP Yes).\n",
      "Area under the curve: 0.8773\n"
     ]
    }
   ],
   "source": [
    "# ROC results\n",
    "library(pROC)\n",
    "rfROC = roc(evalResults$RESP, evalResults$RF, levels=rev(levels(evalResults$RESP)))\n",
    "print(rfROC)\n",
    "FDAROC = roc(evalResults$RESP, evalResults$FDA, levels=rev(levels(evalResults$RESP)))\n",
    "print(FDAROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAOVBMVEUAAAAA/wBNTU1oaGh8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\nAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC\n",
    "plot(rfROC, legacy.axes=TRUE, col=\"red\")\n",
    "plot(FDAROC, legacy.axes=TRUE, add=T, col=\"green\")\n",
    "legend( x=\"bottomright\", c(sprintf(\"RF (%f)\", rfROC$auc), sprintf(\"FDA (%f)\", FDAROC$auc)), \n",
    "       col=c(\"red\", \"green\"), lty=c(1,1,1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review (2):\n",
    "Initial traincontrol and specific parameters:  \n",
    "\n",
    "           AUC  |    Spec   |    Sens\n",
    "    RF:  0.8239 | 0.9641456 | 0.2350842\n",
    "    FDA: 0.8446 | 0.9404727 | 0.3674074\n",
    "\n",
    "    ROC:\n",
    "    RF  | 85.3%\n",
    "    FDA | 87.7%\n",
    "\n",
    "UpSampled:  \n",
    "\n",
    "           AUC  |   Spec |    Sens\n",
    "    RF:  0.9985 | 0.9155 | NA\n",
    "    FDA: 0.8690 | 0.7093 | 0.8450\n",
    "\n",
    "    ROC: \n",
    "    RF  | 84.3% \n",
    "    FDA | 87.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "In conclusion, the FDA model performed better than RF for predicting Response. The classification models used defined control parameters for its traincontrol and the metrics of ROC. The ROC plots that show the AUC of ~85% for RF and ~87% for FDA initially, and ~84% for RF and ~87% for FDA after upsampling. The sensitivity also was NA for RF after upsampled."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
